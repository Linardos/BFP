seed: [0] #[1,2,3,4]
device: 'cpu'
name: 'sanity_check' # use 4digit name tag to overwrite experiment with same parameters
# test_unseen: False # this will turn off train mode and test on a specified center
hyperparameters:
    federated_rounds: 3
    epochs_per_round : 30
    iteration_number: 8 # this will define the number of batches when doing federated (we want the same number of iterations)
    batch_size : 4  # if 0, it will adapt to center
    test_batch_size : 10 #use a higher one for speed up if CUDA memory allows  
    lr : 0.01
    early_stop_counter: 20 # number of iterations after performance stagnation before stopping
    ## MULTI VS BINARY CLASSIFICATION
    criterion : torch.nn.BCELoss
    # criterion : torch.nn.CrossEntropyLoss
    optimizer : torch.optim.SGD
model:
    # The model name used here will generate a new experiment in the ~/mnm/experiments
    arch:
        function: models.nets.ResNet101Classifier
        args: #keyword arguments for function
            pretrained: True
            in_ch: 3
            out_ch: 1
            linear_ch: 512
            early_layers_learning_rate: 1e-5 #10^-5, if set to 0 early layers will be frozen 
            seed: 42 # Particularly important for federated. Models will make no sense if we aggregate from different initializations
    pretrained: # if we have our own weights
        isTrue: False
    continue: True # you have to have continue True and name set to an existing folder you want to continue training on
center: # Ignore this
    UB1: "stge"
    UB2: "jarv"
data:
    pathologies: ['mass'] #,'RV','DCM','MINF'] #, 'RV'] #, 'DCM' ['DCM', 'HCM', 'NOR', 'RV']
    labels: [0,1]
    load_max: 15
paths:
    # Used by client:
    # These are files we send the clients. So the path we define ourselves:
    #landmarks: /home/akis-linardos/BFP/src/preprocessing/optimam_train_hologic_landmarks.pth # out of docker
    landmarks: /BFP/src/preprocessing/optimam_train_hologic_landmarks.pth # in docker
    # ub_logs: workenv/BFP/src/visualizations # Ignore this
    # These are paths we should be given from the partners. The docker should mount them:
    csv_path: /home/lidia-garrucho/datasets/OPTIMAM/png_screening_cropped_fixed/client_images_screening.csv
    dataset_path: /home/lidia-garrucho/datasets/OPTIMAM/png_screening_cropped_fixed/images
    # Used by server:
    logs: BFP/src/server_logs
    experiments: BFP/experiments
    misc: /experiment/misc
