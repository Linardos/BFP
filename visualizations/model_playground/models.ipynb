{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914d1826-c7ed-46da-aead-24969b574b05",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'max_per_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11046/1412167905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0minbreast_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/lidia-garrucho/datasets/INBREAST/AllPNG_cropped\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0minbreast_csv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/lidia-garrucho/datasets/INBREAST/INbreast_updated_cropped_breast.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0minbreast_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mALLDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbreast_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbreast_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inbreast'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/BFP/src/data_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_path, csv_path, data_loader_type, mode, load_max, batch_size)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images_from_subjects_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_ids_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_loader_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'validation'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images_from_subjects_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_ids_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_loader_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BFP/src/data_loader.py\u001b[0m in \u001b[0;36mget_images_from_subjects_simulation\u001b[0;34m(subjects_f, image_id_list)\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# Balance the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mbalance_to_min_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_benign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_malignant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_per_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0mimages_benign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_benign\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbalance_to_min_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0mimages_malignant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_malignant\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbalance_to_min_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'max_per_label'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from src.data_handling.mmg_detection_datasets import *\n",
    "from src.visualizations.plot_image import plot_image_opencv_fit_window\n",
    "from src.data_augmentation.breast_density.data.resize_image import *\n",
    "from src.models import nets\n",
    "from src.data_loader import ALLDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.preprocessing.histogram_standardization import get_hist_stand_landmarks, apply_hist_stand_landmarks\n",
    "\n",
    "# Cropped scans GPU Server\n",
    "# info_csv='/home/lidia-garrucho/datasets/OPTIMAM/png_screening_cropped_fixed/client_images_screening.csv'\n",
    "# dataset_path='/home/lidia-garrucho/datasets/OPTIMAM/png_screening_cropped_fixed/images'\n",
    "inbreast_path=\"/home/lidia-garrucho/datasets/INBREAST/AllPNG_cropped\"\n",
    "inbreast_csv=\"/home/lidia-garrucho/datasets/INBREAST/INbreast_updated_cropped_breast.csv\"\n",
    "inbreast_loader = DataLoader(ALLDataset(inbreast_path, inbreast_csv, mode='train', data_loader_type='inbreast', load_max=20, batch_size=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad2a0d-4bd2-43d1-bfef-0f332d80a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(inbreast_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3efec-a312-4092-a8a8-f54655be08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27eddbe2-2f18-4f7c-a9bf-2e3ad3e4c171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.models.nets.AlexNetClassifier"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nets.AlexNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2dd90-1b5c-4f8e-98be-da00bafa419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_class(name):\n",
    "    module_name, class_name = name.rsplit('.', 1)\n",
    "    module = importlib.import_module(module_name)\n",
    "    return getattr(module, class_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e7de62-c931-453d-9e06-223e5dc95dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import importlib\n",
    "config_file = Path('config.yaml')\n",
    "with open(config_file) as file:\n",
    "  CONFIG = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9031da-23c9-45bd-aad2-580050acb82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "AlexN = nets.AlexNetClassifier(in_ch=1, out_ch=1, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2894cee-45e7-44f1-8d3c-5741b384d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11177025"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet18 = nets.ResNet18Classifier(in_ch=1, out_ch=1, pretrained=False)\n",
    "total_params = sum(param.numel() for param in ResNet18.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1c54a7-ebfe-4066-8ce6-69495eef3952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/home/akis-linardos/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:14: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  \"pytorch_quantization module not found, quantization will not be available\"\n",
      "/home/akis-linardos/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:18: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  \"pytorch_quantization module not found, quantization will not be available\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4008829"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EfficientNetB0 = nets.EfficientNetB0Classifier(in_ch=1, out_ch=1, pretrained=False)\n",
    "total_params = sum(param.numel() for param in EfficientNetB0.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6abbdc96-962c-4fb6-96be-59ffb0da1326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26474209"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DenseNet161 = nets.DenseNet161Classifier(in_ch=1, out_ch=1, pretrained=False)\n",
    "total_params = sum(param.numel() for param in DenseNet161.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f9d729-35dd-4fa4-8cd5-2bf7597abf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23510081"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet50 = nets.ResNet50Classifier(in_ch=1, out_ch=1, pretrained=False)\n",
    "total_params = sum(param.numel() for param in ResNet50.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a113ad28-adfb-431e-9b86-26f0d3fbfca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17550409"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EfficientNetB4 = nets.EfficientNetB4Classifier(in_ch=1, out_ch=1, pretrained=False)\n",
    "total_params = sum(param.numel() for param in EfficientNetB4.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a3befc-d471-4d43-952d-13ae30aab168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6954881"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DenseNet121 = nets.DenseNet121Classifier(in_ch=1, out_ch=1, pretrained=False)\n",
    "total_params = sum(param.numel() for param in DenseNet121.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d8be51-1087-4026-900e-a045c2573653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26474209"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DenseNet161 = nets.DenseNet161Classifier(in_ch=1, out_ch=1, pretrained=False)\n",
    "total_params = sum(param.numel() for param in DenseNet161.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6164475-d36a-4755-889f-edd4121319bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2225153"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MobileNet = nets.MobileNetClassifier(in_ch=1, out_ch=1, pretrained=False)\n",
    "total_params = sum(param.numel() for param in MobileNet.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bf4e864-612a-4cf4-aa04-9fec67a40eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class AlexNetClassifier(nn.Sequential):\n",
    "    def __init__(self, pretrained, in_ch, out_ch, seed=None, early_layers_learning_rate=0):\n",
    "        '''\n",
    "        in_ch = 1 or 3\n",
    "        early_layers can be 'freeze' or 'lower_lr'\n",
    "        '''\n",
    "        super(AlexNetClassifier, self).__init__()\n",
    "        torch.hub._validate_not_a_forked_repo=lambda a,b,c: True # no idea why it's needed, but it supposedly avoids the error \"urllib.error.httperror http error 403 rate limit exceeded\" in some centers\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=pretrained)\n",
    "        # model.classifier[1]=nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1)) # Apply glorot initialization\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.fc = nn.Linear(1000, out_ch) # should adjust this\n",
    "        self.model.classifier[6] = nn.Linear(4096, 1)\n",
    "        \n",
    "\n",
    "        if isinstance(self.model.classifier[6], nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(self.model.classifier[6].weight)\n",
    "            if self.model.classifier[6].bias is not None:\n",
    "                torch.nn.init.zeros_(self.model.classifier[6].bias)\n",
    "\n",
    "        # if out_ch == 1:\n",
    "        #     self.out = nn.Sigmoid()\n",
    "        # else:\n",
    "        self.out = nn.Softmax(dim=1)\n",
    "        super(AlexNetClassifier, self).__init__(self.model,\n",
    "                                                # self.relu,\n",
    "                                                # self.fc,\n",
    "                                                 self.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cf6a8fe7-685b-413e-a677-9903f4ee81de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "AlexNC = AlexNetClassifier(in_ch=1, out_ch=1, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e7bdebc-a954-4d96-9805-ed588b80d23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=False)\n",
    "model.classifier[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2ea923c8-34ce-471c-ba66-d54e6fea2bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "242e8154-a51d-4321-b778-ac16e8383862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlexNC(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81f27aae-8040-4009-aef4-6d24e4bd4624",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19Classifier(nn.Sequential):\n",
    "    def __init__(self, pretrained, in_ch, out_ch, seed=None, early_layers_learning_rate=0):\n",
    "        '''\n",
    "        in_ch = 1 or 3\n",
    "        early_layers can be 'freeze' or 'lower_lr'\n",
    "        '''\n",
    "        super(VGG19Classifier, self).__init__()\n",
    "        torch.hub._validate_not_a_forked_repo=lambda a,b,c: True # no idea why it's needed, but it supposedly avoids the error \"urllib.error.httperror http error 403 rate limit exceeded\" in some centers\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=pretrained)\n",
    "        # model.classifier[1]=nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1)) # Apply glorot initialization\n",
    "        self.model.classifier[6] = nn.Linear(4096, out_ch) # should adjust this\n",
    "\n",
    "        if isinstance(self.model.classifier[6], nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(self.model.classifier[6].weight)\n",
    "            if self.model.classifier[6].bias is not None:\n",
    "                torch.nn.init.zeros_(self.model.classifier[6].bias)\n",
    "\n",
    "        if out_ch == 1:\n",
    "            self.out = nn.Sigmoid()\n",
    "        else:\n",
    "            self.out = nn.Softmax(dim=1)\n",
    "        super(VGG19Classifier, self).__init__(self.model, \n",
    "                                                 self.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45e467a0-a930-468c-97bc-a297a15292b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "VGG19 = VGG19Classifier(in_ch=1, out_ch=1, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc551427-dd49-4233-aca4-1571e8d62750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139574337"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(param.numel() for param in VGG19.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c043b622-dc8b-48ea-89d4-b450d1447480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG19Classifier(\n",
       "  (0): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): ReLU(inplace=True)\n",
       "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (33): ReLU(inplace=True)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8894915a-5db2-4802-9e22-dc6a99bbf954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121Classifier(nn.Sequential):\n",
    "    def __init__(self, pretrained, in_ch, out_ch, seed=None, early_layers_learning_rate=0):\n",
    "        '''\n",
    "        in_ch = 1 or 3\n",
    "        early_layers can be 'freeze' or 'lower_lr'\n",
    "        '''\n",
    "        super(DenseNet121Classifier, self).__init__()\n",
    "        torch.hub._validate_not_a_forked_repo=lambda a,b,c: True # no idea why it's needed, but it supposedly avoids the error \"urllib.error.httperror http error 403 rate limit exceeded\" in some centers\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=pretrained)\n",
    "        # model.classifier[1]=nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1)) # Apply glorot initialization\n",
    "        self.model.fc = nn.Linear(2048, out_ch) # should adjust this\n",
    "\n",
    "        if isinstance(self.model.fc, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(self.model.fc.weight)\n",
    "            if self.model.fc.bias is not None:\n",
    "                torch.nn.init.zeros_(self.model.fc.bias)\n",
    "\n",
    "        if out_ch == 1:\n",
    "            self.out = nn.Sigmoid()\n",
    "        else:\n",
    "            self.out = nn.Softmax(dim=1)\n",
    "        super(ResNet101Classifier, self).__init__(self.model, \n",
    "                                                 self.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a6205a48-651e-4ca1-8294-fc4f00301b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "pretrained=False\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "42b95c35-d1cc-441c-a8ef-a4e2da9a7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/home/akis-linardos/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:14: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  \"pytorch_quantization module not found, quantization will not be available\"\n",
      "/home/akis-linardos/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:18: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  \"pytorch_quantization module not found, quantization will not be available\"\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c2c19e4a-1f4a-45cc-9122-9b132e8f46b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (stem): Sequential(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (activation): SiLU(inplace=True)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=32, out_features=8, bias=True)\n",
       "          (expand): Linear(in_features=8, out_features=32, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=96, out_features=4, bias=True)\n",
       "          (expand): Linear(in_features=4, out_features=96, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=144, out_features=6, bias=True)\n",
       "          (expand): Linear(in_features=6, out_features=144, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=144, out_features=6, bias=True)\n",
       "          (expand): Linear(in_features=6, out_features=144, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=240, out_features=10, bias=True)\n",
       "          (expand): Linear(in_features=10, out_features=240, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=240, out_features=10, bias=True)\n",
       "          (expand): Linear(in_features=10, out_features=240, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block3): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (conv): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (activation): SiLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (squeeze): Flatten()\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
