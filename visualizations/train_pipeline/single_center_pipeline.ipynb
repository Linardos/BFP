{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda0c6cf-b7cf-483e-b575-65e2322ef88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchvision.datasets import CIFAR10\n",
    "import flwr as fl\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/akis-linardos/BFP/src')\n",
    "from models import nets\n",
    "from data_loader import ALLDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "# from sklearn import roc_auc_score\n",
    "# import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb860589-16ee-4994-9cfc-04ed7af7a731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here dataset path /home/akis-linardos/Datasets\n",
      "Here csv path /home/akis-linardos/Datasets/CMMD/info.csv\n"
     ]
    }
   ],
   "source": [
    "def import_class(name):\n",
    "    module_name, class_name = name.rsplit('.', 1)\n",
    "    module = importlib.import_module(module_name)\n",
    "    return getattr(module, class_name)\n",
    "\n",
    "HOME_PATH = Path.home()\n",
    "\n",
    "config_file = 'config.yaml'\n",
    "with open(config_file) as file:\n",
    "  CONFIG = yaml.safe_load(file)\n",
    "\n",
    "CSV_PATH = os.environ['csv_path']\n",
    "DATASET_PATH = os.environ['dataset_path']\n",
    "# Before running each client locally, you need to set the environment variable client_log_path to a unique value for each worker\n",
    "\n",
    "DATA_LOADER_TYPE= os.getenv('data_loader_type',\"optimam\") #env variable data_loader if not given default to optimam type dataloading\n",
    "\n",
    "# Docker ip is: 172.17.0.3\n",
    "print(f'Here dataset path {DATASET_PATH}')\n",
    "print(f'Here csv path {CSV_PATH}')\n",
    "\n",
    "DEVICE = torch.device(CONFIG['device']) #if torch.cuda.is_available() else \"cpu\")\n",
    "CRITERION = import_class(CONFIG['hyperparameters']['criterion'])\n",
    "\n",
    "\n",
    "log_dict = {'local_loss':{0:[]}, 'local_val_loss':{0:[]}, 'local_accuracy':[], 'local_sensitivity':[], 'local_specificity':[], 'local_val_predictions':[],\n",
    "            'local_true_positives':[],'local_false_positives':[],'local_false_negatives':[],'local_true_negatives':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96dfcda-f372-4408-a1ad-2fb99bfcef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load Breast Cancer training and validation set.\"\"\"\n",
    "    print('Loading data...')\n",
    "    training_loader = DataLoader(ALLDataset(DATASET_PATH, CSV_PATH, mode='train', data_loader_type=DATA_LOADER_TYPE, load_max=CONFIG['data']['load_max']), batch_size=CONFIG['hyperparameters']['batch_size'])\n",
    "    validation_loader = DataLoader(ALLDataset(DATASET_PATH, CSV_PATH, mode='val', data_loader_type=DATA_LOADER_TYPE, load_max=CONFIG['data']['load_max']), batch_size=CONFIG['hyperparameters']['batch_size'])\n",
    "    test_loader = DataLoader(ALLDataset(DATASET_PATH, CSV_PATH, mode='test', data_loader_type=DATA_LOADER_TYPE, load_max=CONFIG['data']['load_max']), batch_size=CONFIG['hyperparameters']['batch_size'])\n",
    "    print(len(training_loader))\n",
    "    return training_loader, validation_loader #test_loader\n",
    "\n",
    "def train(net, training_loader, criterion):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    losses = []\n",
    "    cumulative_loss = 0.0\n",
    "    predictions = []\n",
    "    print('Training...')\n",
    "    current_round_num=list(log_dict['local_loss'].keys())[-1]\n",
    "    next_round_num=current_round_num+1\n",
    "    log_dict['local_loss'][next_round_num]=[] # A key for the next round is generated. Final round will always remain empty\n",
    "    for _ in range(CONFIG['hyperparameters']['epochs_per_round']):\n",
    "        for i, batch in enumerate(tqdm(training_loader)):\n",
    "            images, labels = batch[0].to(DEVICE), batch[1].to(DEVICE).unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(images), labels)\n",
    "            cumulative_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    train_results = cumulative_loss #(losses, predictions)\n",
    "    return train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3511c5d-c865-4848-b490-285846faba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities_to_labels(predictions : torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Convert the network's predictions to labels.\"\"\"\n",
    "    if predictions.size()[1]==1: # if not one hot encoding\n",
    "        return torch.round(predictions) #sigmoid outputs\n",
    "    predictions = predictions.detach().numpy()\n",
    "    predictions_as_labels = []\n",
    "    for row in predictions:\n",
    "        predictions_as_labels.append(np.argmax(row))\n",
    "    return torch.Tensor(predictions_as_labels)\n",
    "\n",
    "def test(net, validation_loader, criterion):\n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    correct, total, cumulative_loss = 0, 0, 0.0\n",
    "    false_positive, false_negative, true_positive, true_negative = 0, 0, 0, 0\n",
    "    predictions, val_losses = [], []\n",
    "    current_round_num=list(log_dict['local_val_loss'].keys())[-1]\n",
    "    next_round_num=current_round_num+1\n",
    "    log_dict['local_val_loss'][next_round_num]=[] # A key for the next round is generated. Final round will always remain empty\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(validation_loader)):\n",
    "            images, labels = batch[0].to(DEVICE), batch[1].to(DEVICE).unsqueeze(1)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels).item()\n",
    "            cumulative_loss += criterion(outputs, labels).item()\n",
    "            predicted = probabilities_to_labels(outputs.data)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            false_positive += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            false_negative += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "            true_positive += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            true_negative += ((predicted == 0) & (labels == 0)).sum().item()\n",
    "            predictions.append(predicted)\n",
    "            val_losses.append(loss)\n",
    "    val_loss=sum(val_losses)/len(val_losses)\n",
    "    log_dict['local_val_loss'][current_round_num]=val_loss\n",
    "    accuracy = correct / total\n",
    "    # sensitivity = true_positive.sum().item() / (true_positive.sum().item() + false_negative.sum().item())\n",
    "    # specificity = true_negative.sum().item() / (true_negative.sum().item() + false_positive.sum().item())\n",
    "    # AUC = roc_auc_score(labels.detach().numpy(), outputs.detach().numpy())\n",
    "    log_dict['local_accuracy'].append(accuracy)\n",
    "    # log_dict['local_sensitivity'].append(sensitivity)\n",
    "    # log_dict['local_specificity'].append(specificity)\n",
    "    # Store everything!\n",
    "    log_dict['local_true_positives'].append(true_positive)\n",
    "    log_dict['local_true_negatives'].append(true_negative)\n",
    "    log_dict['local_false_positives'].append(false_positive)\n",
    "    log_dict['local_false_negatives'].append(false_negative)\n",
    "\n",
    "    loss = cumulative_loss / total\n",
    "    # import pdb; pdb.set_trace()\n",
    "    # test_results = (loss, accuracy, bytes(predictions))\n",
    "    test_results = (loss, accuracy)\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd51266f-7af9-461a-822c-f449a80023c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Total images selected by status (benign): 1108\n",
      "Total images selected by status (malignant): 1108\n",
      "Total images selected by status (benign): 1108\n",
      "Total images selected by status (malignant): 1108\n",
      "Total images selected by status (benign): 1108\n",
      "Total images selected by status (malignant): 1108\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "train_loader, validation_loader = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51737790-8c11-4dd8-ba5c-14c50d878129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/akis-linardos/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "net = nets.ResNet101Classifier(in_ch=3, out_ch=1, pretrained=False)\n",
    "net.to(DEVICE)\n",
    "criterion=CRITERION()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46a3cdde-8f30-4f91-bedc-3610ee15b7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 45/45 [00:07<00:00,  6.13it/s]\n"
     ]
    }
   ],
   "source": [
    "test_results = test(net, validation_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8baaf9ba-336e-4fb2-8658-dfda68277153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09248985907247474, 0.509009009009009)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
