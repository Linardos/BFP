seed: [0] #[1,2,3,4]
device: 'cuda'
name: 'sanity_check_Everycenter_30epr1fr_BALANCED' # use 4digit name tag to overwrite experiment with same parameters
# test_unseen: False # this will turn off train mode and test on a specified center
strategy:
    min_available_clients: 3 # Change to increase the number of expected clients
    min_fit_clients: 3 
    min_eval_clients: 3
    CD_P: 1.0 # Center Dropout [Percentage] Note that end result will default to min_fit_clients if CD_P results in a lower number of clients.
hyperparameters:
    federated_rounds: 1
    epochs_per_round : 30 # 
    batch_size : 10  # if 0, it will adapt to center
    test_batch_size : 10 #use a higher one for speed up if CUDA memory allows  
    lr : 0.01
    early_stop_counter: 20 # number of iterations after performance stagnation before stopping
    ## MULTI VS BINARY CLASSIFICATION
    criterion : torch.nn.BCELoss
    # criterion : torch.nn.CrossEntropyLoss
    optimizer : torch.optim.SGD
model:
    # The model name used here will generate a new experiment in the ~/mnm/experiments
    arch:
        function: models.nets.ResNet101Classifier
        args: #keyword arguments for function
            pretrained: True
            in_ch: 1
            out_ch: 1
            early_layers_learning_rate: 1e-5 #10^-5, if set to 0 early layers will be frozen 
            seed: 42 # Particularly important for federated. Models will make no sense if we aggregate from different initializations
    pretrained: # if we have our own weights
        isTrue: False
center: # Ignore this
    UB1: "stge"
    UB2: "jarv"
data:
    pathologies: ['mass'] #,'RV','DCM','MINF'] #, 'RV'] #, 'DCM' ['DCM', 'HCM', 'NOR', 'RV']
    labels: [0,1]
    load_max: 15
    balance: True
paths:
    # Used by client:
    # These are files we send the clients. So the path we define ourselves:
    #landmarks: /home/akis-linardos/BFP/src/preprocessing/optimam_train_hologic_landmarks.pth # out of docker
    landmarks: /BFP/src/preprocessing/optimam_train_hologic_landmarks.pth # in docker
    # ub_logs: workenv/BFP/src/visualizations # Ignore this
    # These are paths we should be given from the partners. The docker should mount them:
    csv_path: /home/lidia-garrucho/datasets/OPTIMAM/png_screening_cropped_fixed/client_images_screening.csv
    dataset_path: /home/lidia-garrucho/datasets/OPTIMAM/png_screening_cropped_fixed/images
    # Used by server:
    # logs: BFP/src/server_logs
    experiments: BFP/src/experiments
    misc: /experiment/misc
    continue_from_checkpoint: False #/experiments/experiment_folder # If true change False with path to current experiment folder (Not path to checkpoint)
